\section*{Question 2}

Let \( T_{\mu} \) be the Bellman operator defined in the above question. \\
Show that \( T_{\mu} \) is a \( \gamma \)--contraction with respect to \( {\Vert \cdot \Vert}_{D_{\mu}} \).

\subsection*{Solution}

\begin{definition}
    The \( D_{\mu} \) norm is defined as
    \[
        \Vert J \Vert_{D_{\mu}}^2
        =
        J^{\top} D_{\mu} J
        =
        \sum_{s=1}^{S} d_{\mu}(s) J^2(s)
    \]
    where \( D_{\mu} \) is a diagonal matrix with the elements of \( d_\mu \) on the diagonal, and \( J \in \mathbb{R}^{S} \).
\end{definition}

\begin{definition}
    A mapping \( F: \mathbb{R}^{S} \to \mathbb{R}^{S} \) is a contraction mapping with respect to the \( D_{\mu} \) norm if there exists a constant \( \kappa \in [0, 1) \) such that
    \[
        \Vert F J_{1} - F J_{2} \Vert_{D_{\mu}} \leq \kappa \Vert J_{1} - J_{2} \Vert_{D_{\mu}}
        \qquad \forall J_{1}, J_{2} \in \mathbb{R}^{S}
    \]
\end{definition}

\begin{lemma}\label{P_mu-contraction}
    \( P_{\mu} \) is a contraction mapping with respect to the \( D_{\mu} \) norm.
\end{lemma}

\begin{proof}
    By definition of the weighted norm, we have
    \[
        \|P_\mu J_{1} - P_\mu J_{2}\|_{D_\mu}^{2}
        =
        \sum_{s=1}^{S} d_\mu(s)\,\bigl[(P_\mu J_{1})(s) - (P_\mu J_{2})(s)\bigr]^{2}.
    \]
    \[
        \because
        (P_\mu J)(s)
        =
        \sum_{s'} P_\mu(s,s')\,J(s')
    \]
    \[
        \implies
        (P_\mu J_{1})(s) - (P_\mu J_{2})(s)
        =
        \sum_{s'} P_\mu(s,s')\,\bigl(J_{1}(s') - J_{2}(s')\bigr).
    \]
    Since \( \{ P_\mu(s,s') \} _{s'}\) is a probability distribution over \(s'\), Jensenâ€™s inequality gives
    \[
        \Bigl(\sum_{s'} P_\mu(s,s')\,[J_{1}(s') - J_{2}(s')]\Bigr)^{2}
        \;\le\;
        \sum_{s'} P_\mu(s,s')\,[J_{1}(s') - J_{2}(s')]^{2}.
    \]
    \begin{align*}
        \implies
        \|P_\mu J_{1} - P_\mu J_{2}\|_{D_\mu}^{2}
        \; & \le\;
        \sum_{s=1}^{S} d_\mu(s)\,\sum_{s'} P_\mu(s,s')\,[J_{1}(s') - J_{2}(s')]^{2}.
        \\ & =
        \sum_{s'}\Bigl(\sum_{s} d_\mu(s)\,P_\mu(s,s')\Bigr)\,[J_{1}(s') - J_{2}(s')]^{2}.
    \end{align*}
    But \(d_\mu\) is the stationary distribution of \(P_\mu\), so \(\sum_{s} d_\mu(s)\,P_\mu(s,s')=d_\mu(s')\).  Hence
    \[
        \|P_\mu J_{1} - P_\mu J_{2}\|_{D_\mu}^{2}
        \;\le\;
        \sum_{s'} d_\mu(s')\,[J_{1}(s') - J_{2}(s')]^{2}
        =
        \|J_{1} - J_{2}\|_{D_\mu}^{2}.
    \]
    \[
        \implies
        \|P_\mu J_{1} - P_\mu J_{2}\|_{D_\mu}
        \le
        \|J_{1} - J_{2}\|_{D_\mu}.
    \]
\end{proof}

\begin{theorem}
    \( T_{\mu} \) is a \( \gamma \)--contraction with respect to the \( D_{\mu} \) norm.
    \[
        \Vert T_{\mu} J_{1} - T_{\mu} J_{2} \Vert_{D_{\mu}} \leq \gamma \Vert J_{1} - J_{2} \Vert_{D_{\mu}}
    \]
    for all \( J_{1}, J_{2} \in \mathbb{R}^{S} \), and for some \( \gamma \in [0, 1) \).
\end{theorem}

\begin{proof}
    Starting with the left-hand side, we have
    \begin{align*}
        \Vert T_{\mu} J_{1} - T_{\mu} J_{2} \Vert_{D_{\mu}}
         & =
        \Vert \cancel{r_{\mu}} + \gamma P_{\mu} J_{1} - \cancel{r_{\mu}} - \gamma P_{\mu} J_{2} \Vert_{D_{\mu}}
        \\
         & =
        \Vert \gamma P_{\mu} J_{1} - \gamma P_{\mu} J_{2} \Vert_{D_{\mu}}
        =
        \gamma \Vert P_{\mu} J_{1} - P_{\mu} J_{2} \Vert_{D_{\mu}}
        \\
         & \leq
        \gamma \Vert J_{1} - J_{2} \Vert_{D_{\mu}}
    \end{align*}
    where the last step follows from the fact that \( P_{\mu} \) is a contraction mapping with respect to the \( D_{\mu} \) norm (Lemma~\ref{P_mu-contraction}).
\end{proof}
