# RL | 2025-02-11

## Infinite horizon discounted cost problems

Setting involves no termination state

$$
S = \{ 1, 2, \dots, n \}
$$

$A(i) \triangleq$ Set of feasible actions in state $i$

$A = \bigcup_{i \in S} A(i) \triangleq$ Set of all actions

As before, we still have $\vert S \vert < \infty$, $\vert A \vert < \infty$

$$
J^*(i) = \min_{\mu} \operatorname{E} \left[ \sum_{k = 0}^{\infty} \alpha^k g(i_k, \mu(i_k), i_{k+1}) \mid i_0 = i \right]
$$

Here $0 < \alpha < 1$ is called the **discount factor**

$$
J^*(i) \equiv \text{Value of state } i \quad \text{or} \quad \text{Cost-to-go from state } i
$$

Let $J = (J(1), \ J(2), \ \dots, \ J(n))$. Define operators $T$ and $T_\mu$ as

$$
(TJ)(i) = \min_{u \in A(i)} \sum_{j = 1}^{n} p_{ij}(u) \Big( g(i, u, j) + \alpha J(j) \Big), \quad i \in S
$$

$$
(T_\mu J)(i) = \sum_{j = 1}^{n} p_{ij}(\mu(i)) \Big( g(i, \mu(i), j) + \alpha J(j) \Big), \quad i \in S
$$

Let

$$
P_\mu =
\begin{bmatrix}
p_{11}(\mu(1)) & p_{12}(\mu(1)) & \dots & p_{1n}(\mu(1)) \\
p_{21}(\mu(2)) & p_{22}(\mu(2)) & \dots & p_{2n}(\mu(2)) \\
\vdots & \vdots & \ddots & \vdots \\
p_{n1}(\mu(n)) & p_{n2}(\mu(n)) & \dots & p_{nn}(\mu(n)) \\
\end{bmatrix}_{n \times n}
$$

**Note:** $P_\mu$ is a stochastic matrix because

$$
\sum_{j \in S} p_{ij}(\mu(i)) = 1 \quad \forall i \in S
$$

The row sum is $1$ here.

Previously, in finite horizon problems, this row sum was less than $1$, due to the presence of terminal states.

Let

$$
g_\mu =
\begin{bmatrix}
\sum_{j = 1}^{n} p_{1j}(\mu(1)) \ g(1, \mu(1), j) \\
\sum_{j = 1}^{n} p_{2j}(\mu(2)) \ g(2, \mu(2), j) \\
\vdots \\
\sum_{j = 1}^{n} p_{nj}(\mu(n)) \ g(n, \mu(n), j)
\end{bmatrix}_{n \times 1}
$$

**Bellman equation** under a given policy $\mu$

$$
T_\mu J = g_\mu + \alpha P_\mu J = J
$$

### Lemma-1: Monotonicity lemma

For any vectors $J, \bar J \in \mathbb{R}^n$, s.t. $J(i) \leq \bar J(i), \ \forall i \in S$ and for any stationary policy $\mu$

1.
$$
(T^k J)(i) \leq (T^k \bar J)(i), \quad \forall k \geq 0, \quad \forall i \in S, \quad k = 1, 2, \dots
$$

2.
$$
(T_\mu^k J)(i) \leq (T_\mu^k \bar J)(i), \quad \forall k \geq 0, \quad \forall i \in S, \quad k = 1, 2, \dots
$$

Substituting $\alpha = 1$ gives the Stochastic shortest path problem.

---

Let $e = \underbrace{ (1, 1, \dots, 1) }_{n-\text{vector}}$. Then for any vector $J = (J(1), \ J(2), \ \dots, \ J(n))$ and $r \in \mathbb{R}$

$$
\begin{aligned}
(T (J + re))(i)
& =
\min_{u \in A(i)} \sum_{j = 1}^{n} p_{ij}(u) \Big( g(i, u, j) + \alpha (J + re)(j) \Big)
\\ & =
\min_{u \in A(i)} \sum_{j = 1}^{n} p_{ij}(u) \Big( g(i, u, j) + \alpha J(j) \Big) + \alpha r
\\ & =
(T J)(i) + \alpha r
\end{aligned}
$$

or

$$
T (J + re) = T J + \alpha r e
$$

### Lemma-2

For every $k \geq 0$, vector $J$, stationary $\mu$ and scalar $r$,

1.
$$
\left( T^k (J + re) \right) (i) \leq (T^k J)(i) + \alpha^k r, \quad \forall \ i = 1, 2, \dots, n, \quad k \geq 1
$$

2.
$$
\left( T_\mu^k (J + re) \right) (i) \leq (T_\mu^k J)(i) + \alpha^k r, \quad \forall \ i = 1, 2, \dots, n, \quad k \geq 1
$$

Proof will follow from ~mathematical induction.

---

We can construct a DCP to a SSPP by adding a termination state

![Converting a DCP problem to SSPP problem](./TeX/2025-02-11/1.png){ width=90% }

---

Probability of termination in $1^{\text{st}}$ stage $= 1 - \alpha$

Probability of termination in $2^{\text{nd}}$ stage $= \alpha(1 - \alpha)$

Probability of termination in $k^{\text{th}}$ stage $= \alpha^{k-1}(1 - \alpha)$

$$
\begin{aligned}
\implies
\text{Probability of non-termination even in } k^{\text{th}} \text{ stage}
& =
1 - \left\{ (1 - \alpha) (1 + \alpha + \alpha^2 + \dots + \alpha^{k-1}) \right\}
\\ & =
1 - (1 - \alpha) \frac{(1 - \alpha^k)}{(1 - \alpha)} = \alpha^k
\end{aligned}
$$

$$
\text{Expected single stage cost in the } k^{\text{th}} \text{ stage} = \alpha^k \sum_{j = 1}^{n} p_{ij}(u) \ g(i, u, j)
$$

All the policies are proper for the associated SSPP since from every state under every policy, there is a probability of $(1 - \alpha)$ of termination. Also, for DCP, expected single state cost at $k^{\text{th}}$ stage is

$$
\text{Expected single stage cost at } k^{\text{th}} \text{ stage} = \alpha^k \sum_{j = 1}^{n} p_{ij}(u) \ g(i, u, j)
$$

where $\alpha$ is the discount factor.

$g(i, u, 0) = 0$ in the equivalence

---

Consider now a DCP where $\vert g(i, u, j) \vert \leq M, \ \forall i, j \in S, \ u \in A(i)$

### Proposition: DP convergence

For any bounded $J: S \to \mathbb{R}$, the optimal cost function satisfies,

$$
J^*(i) = \lim_{N \to \infty} (T^N J)(i), \quad \forall i \in S
$$

#### Proof

Consider a policy $\pi = \{ \mu_0, \mu_1, \dots \}$ with $\mu_k: S \to A$ such that $\mu_k(i) \in A(i), \ \forall i \in S, \ k \geq 0$. Then

$$
\begin{aligned}
J_{\pi}(i)
& =
\lim_{N \to \infty} \operatorname{E} \left[ \sum_{k=0}^{N-1} \alpha^k g(i_k, \mu_k(i_k), i_{k+1}) \Bigg| i_0 = i \right]
\\ & =
\lim_{N \to \infty} \operatorname{E} \left[ \left( \sum_{k=0}^{K-1} \alpha^k g(i_k, \mu_k(i_k), i_{k+1}) + \sum_{k=K}^{N-1} \alpha^k g(i_k, \mu_k(i_k), i_{k+1}) \right) \Bigg| i_0 = i \right]
\\ & =
\operatorname{E} \left[ \sum_{k=0}^{K-1} \alpha^k g(i_k, \mu_k(i_k), i_{k+1}) \Bigg| i_0 = i \right]
+
\lim_{N \to \infty} \operatorname{E} \left[ \sum_{k=K}^{N-1} \alpha^k g(i_k, \mu_k(i_k), i_{k+1}) \Bigg| i_0 = i \right]
\end{aligned}
$$

Since $\vert g(i_k, \mu_k(i_k), i_{k+1}) \vert \leq M, \ \forall i_k, i_{k+1} \in S, \ \mu_k(i_k) \in A(i_k)$,

$$
\left\vert \lim_{N \to \infty} \operatorname{E} \left[ \sum_{k=K}^{N-1} \alpha^k g(i_k, \mu_k(i_k), i_{k+1}) \Bigg| i_0 = i \right] \right\vert \leq M \sum_{k=K}^{N-1} \alpha^k = \frac{\alpha^k M}{1 - \alpha}
$$

Thus,

$$
\operatorname{E} \left[ \sum_{k=0}^{K-1} \alpha^k g(i_k, \mu_k(i_k), i_{k+1}) \Bigg| i_0 = i \right] = J_{\pi}(i) - \lim_{N \to \infty} \operatorname{E} \left[ \sum_{k=K}^{N-1} \alpha^k g(i_k, \mu_k(i_k), i_{k+1}) \Bigg| i_0 = i \right]
$$

$$
\begin{aligned}
\implies &
J_{\pi}(i) - \frac{\alpha^k M}{1 - \alpha} - \alpha^k \max_{j \in S} \vert J(j) \vert
\\ & \leq
\operatorname{E} \left[ \sum_{k=0}^{K-1} \alpha^k g(i_k, \mu_k(i_k), i_{k+1}) + \alpha^k J(i_k) \Bigg| i_0 = i \right]
\\ & \leq
J_{\pi}(i) + \frac{\alpha^k M}{1 - \alpha} + \alpha^k \max_{j \in S} \vert J(j) \vert
\end{aligned}
$$

Taking the $\min$ over $\pi$ on all sides, we have for all $i \in S$ and $k > 0$,

$$
\implies J^*(i) - \frac{\alpha^k M}{1 - \alpha} - \alpha^k \max_{j \in S} \vert J(j) \vert
\leq (T^k J)(i) \leq
J^*(i) + \frac{\alpha^k M}{1 - \alpha} + \alpha^k \max_{j \in S} \vert J(j) \vert
$$

Letting $k \to \infty$ on all sides,

$$
\lim_{k \to \infty} (T^k J)(i) = J^*(i)
$$

### Corollary: DP convergence for a given policy $\mu$

For every stationary policy $\mu$, the associated cost function satisfies,

$$
J_{\mu}(i) = \lim_{N \to \infty} (T_\mu^N J)(i), \quad \forall i \in S, \ \text{ and any } J \in \mathbb{R}^{\vert S \vert}
$$

#### Proof

Consider an alternate MDP where

$$
A(i) = \{ \mu(i) \}, \quad \forall \ i \in S
$$

### Proposition: Bellman equation

The optimal cost function $J^*$ satisfies

$$
\begin{aligned}
J^*(i)
& =
\min_{\mu \in A(i)} \sum_{j \in S} p_{ij}(u) \Big( g(i, u, j) + \alpha J^*(j) \Big), \quad \forall \ i \in S
\\
\text{or }
J^*
& =
T J^*
\end{aligned}
$$

Moreover, $J^*$ is the unique solution to the equation within the class of boundary functions.

#### Proof

Recall

$$
J^*(i) - \frac{\alpha^k M}{1 - \alpha} - \alpha^k \max_{j \in S} \vert J(j) \vert
\leq (T^k J)(i) \leq
J^*(i) + \frac{\alpha^k M}{1 - \alpha} + \alpha^k \max_{j \in S} \vert J(j) \vert
$$

Applying $T$ on all sides,

$$
(T J^*)(i) - \frac{\alpha^{k+1} M}{1 - \alpha} - \alpha^{k+1} \max_{j \in S} \vert J(j) \vert
\leq (T^{k+1} J)(i) \leq
(T J^*)(i) + \frac{\alpha^{k+1} M}{1 - \alpha} + \alpha^{k+1} \max_{j \in S} \vert J(j) \vert
$$

Let $k \to \infty$ on all sides gives us,

$$
\begin{aligned}
(T J^*)(i) & \leq J^*(i) \leq (T J^*)(i)
\\
\text{or }
T J^* & = J^*
\end{aligned}
$$

**Uniqueness**

Suppose $\bar J \in \mathbb{R}^n$ is another solution,
$$
\bar J = T \bar J = T^2 \bar J = T^3 \bar J = \dots = \lim_{k \to \infty} T^k \bar J = J^*
\implies \bar J = J^*
$$

---

