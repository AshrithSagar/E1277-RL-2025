# RL | 2025-02-11

## Infinite horizon discounted cost problems

Setting involves no termination state

$$
S = \{ 1, 2, \dots, n \}
$$

$A(i) \triangleq$ Set of feasible actions in state $i$

$A = \bigcup_{i \in S} A(i) \triangleq$ Set of all actions

As before, we still have $\vert S \vert < \infty$, $\vert A \vert < \infty$

$$
J^*(i) = \min_{\mu} \operatorname{E} \left[ \sum_{k = 0}^{\infty} \alpha^k g(i_k, \mu(i_k), i_{k+1}) \mid i_0 = i \right]
$$

Here $0 < \alpha < 1$ is called the **discount factor**

$$
J^*(i) \equiv \text{Value of state } i \quad \text{or} \quad \text{Cost-to-go from state } i
$$

Let $J = (J(1), \ J(2), \ \dots, \ J(n))$. Define operators $T$ and $T_\mu$ as

$$
(TJ)(i) = \min_{u \in A(i)} \sum_{j = 1}^{n} p_{ij}(u) \Big( g(i, u, j) + \alpha J(j) \Big), \quad i \in S
$$

$$
(T_\mu J)(i) = \sum_{j = 1}^{n} p_{ij}(\mu(i)) \Big( g(i, \mu(i), j) + \alpha J(j) \Big), \quad i \in S
$$

Let

$$
P_\mu =
\begin{bmatrix}
p_{11}(\mu(1)) & p_{12}(\mu(1)) & \dots & p_{1n}(\mu(1)) \\
p_{21}(\mu(2)) & p_{22}(\mu(2)) & \dots & p_{2n}(\mu(2)) \\
\vdots & \vdots & \ddots & \vdots \\
p_{n1}(\mu(n)) & p_{n2}(\mu(n)) & \dots & p_{nn}(\mu(n)) \\
\end{bmatrix}_{n \times n}
$$

**Note:** $P_\mu$ is a stochastic matrix because

$$
\sum_{j \in S} p_{ij}(\mu(i)) = 1 \quad \forall i \in S
$$

The row sum is $1$ here.

Previously, in finite horizon problems, this row sum was less than $1$, due to the presence of terminal states.

Let

$$
g_\mu =
\begin{bmatrix}
\sum_{j = 1}^{n} p_{1j}(\mu(1)) \ g(1, \mu(1), j) \\
\sum_{j = 1}^{n} p_{2j}(\mu(2)) \ g(2, \mu(2), j) \\
\vdots \\
\sum_{j = 1}^{n} p_{nj}(\mu(n)) \ g(n, \mu(n), j)
\end{bmatrix}_{n \times 1}
$$

**Bellman equation** under a given policy $\mu$

$$
T_\mu J = g_\mu + \alpha P_\mu J = J
$$

### Lemma-1: Monotonicity lemma

For any vectors $J, \bar J \in \mathbb{R}^n$, s.t. $J(i) \leq \bar J(i), \ \forall i \in S$ and for any stationary policy $\mu$

1.
$$
(T^k J)(i) \leq (T^k \bar J)(i), \quad \forall k \geq 0, \quad \forall i \in S, \quad k = 1, 2, \dots
$$

2.
$$
(T_\mu^k J)(i) \leq (T_\mu^k \bar J)(i), \quad \forall k \geq 0, \quad \forall i \in S, \quad k = 1, 2, \dots
$$

Substituting $\alpha = 1$ gives the Stochastic shortest path problem.

---

Let $e = \underbrace{ (1, 1, \dots, 1) }_{n-\text{vector}}$. Then for any vector $J = (J(1), \ J(2), \ \dots, \ J(n))$ and $r \in \mathbb{R}$

$$
\begin{aligned}
(T (J + re))(i)
& =
\min_{u \in A(i)} \sum_{j = 1}^{n} p_{ij}(u) \Big( g(i, u, j) + \alpha (J + re)(j) \Big)
\\ & =
\min_{u \in A(i)} \sum_{j = 1}^{n} p_{ij}(u) \Big( g(i, u, j) + \alpha J(j) \Big) + \alpha r
\\ & =
(T J)(i) + \alpha r
\end{aligned}
$$

or

$$
T (J + re) = T J + \alpha r e
$$

### Lemma-2

For every $k \geq 0$, vector $J$, stationary $\mu$ and scalar $r$,

1.
$$
\left( T^k (J + re) \right) (i) \leq (T^k J)(i) + \alpha^k r, \quad \forall \ i = 1, 2, \dots, n, \quad k \geq 1
$$

2.
$$
\left( T_\mu^k (J + re) \right) (i) \leq (T_\mu^k J)(i) + \alpha^k r, \quad \forall \ i = 1, 2, \dots, n, \quad k \geq 1
$$

Proof will follow from ~mathematical induction.

---

We can construct a DCP to a SSPP by adding a termination state

![Converting a DCP problem to SSPP problem](./TeX/2025-02-11/1.png){ width=90% }

---

Probability of termination in $1^{\text{st}}$ state $= 1 - \alpha$

Probability of termination in $2^{\text{nd}}$ state $= \alpha(1 - \alpha)$

Probability of termination in $k^{\text{th}}$ state $= \alpha^{k-1}(1 - \alpha)$
$$
\begin{aligned}
\implies
\text{Probability of non-termination even in } k^{\text{th}} \text{ state}
& =
1 - \left\{ (1 - \alpha) (1 + \alpha + \alpha^2 + \dots + \alpha^{k-1}) \right\}
\\ & =
1 - (1 - \alpha) \frac{(1 - \alpha^k)}{(1 - \alpha)} = \alpha^k
\end{aligned}
$$
Expected single stage cost in the $k^{\text{th}}$ state

---

