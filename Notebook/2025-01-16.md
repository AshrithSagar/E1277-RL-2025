# RL | 2025-01-16

## Markov decision process (MDP)

State space $S$, action spce $A$

Problem of optimal control.

### Controlled Markov chain (CMC)

Given state $S$, let $A(s)$ be the set of feasible actions in state $s$. Then $A = \bigcup_{s \in S} A(s)$.

Let $\{ X_n \}$ be a stochastic process that depends on a control valued sequence $\{ Z_n \}$. We assume that $Z_n \in A(X_n), \ \forall \ n$. Then $\{ X_n \}$ is a controlled Markov chain if
$$
\begin{aligned}
&
P(X_{n+1} = j \mid X_n = i, Z_n = a, X_{n-1} = i_{n-1}, Z_{n-1} = a_{n-1}, \dots, X_0 = i_0, Z_0 = a_0)
\\ & \qquad =
P(X_{n+1} = j \mid X_n = i, Z_n = a), \quad \forall \ n
\\ & \qquad \triangleq
P(i, a, j)
\end{aligned}
$$
~ Similar to a Markov chain; In MC, only state evolutions happen.

---

