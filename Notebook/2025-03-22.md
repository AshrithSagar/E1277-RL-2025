# RL | 2025-03-22

## Policy evaluation with function approximation ($TD(0)$)

- $Q$-learning
  - Tabular approach
  - Function approximation $\leftarrow$ D$Q$N
    - Works well when state and action space are finite

$$
\theta_{n+1} = \theta_n + \alpha_n \, \delta_n \, \phi(s_n), \qquad \text{where } \delta_n = r(s_n, a_n) + \gamma \, \phi^\top(s_n') \, \theta_n - \phi^\top(s_n) \, \theta_n
$$

$$
\theta_{n+1} = \theta_n + \alpha_n \, \big[ h(\theta_n) + M_{n+1} \big], \qquad \text{where } b = \phi^\top \, D_\mu \, r_\mu, \quad A = \phi^\top \, D_\mu \, (\mathcal{I} - \gamma P_\mu) \, \phi
$$

$$
\mathbb{E}{\Vert M_n \Vert}^2 < \infty, \quad \mathbb{E} \big[ M_{n+1} \mid \mathcal{F}_n \big] = 0
$$

Need to show that

$$
\mathbb{E} \big[ {\Vert M_{n+1} \Vert}^2 \mid \mathcal{F}_n \big] \leq k \Big[ 1 + {\Vert \theta_n \Vert}^2 \Big]
$$

**Conditional expressions:**

$\underbrace{\mathbb{E}[X \mid G]}_{\text{Random variable}} \to$ Best representation of $X$ given the knowledge of $G$

$\underbrace{X}_{\text{Random variable}} \mid \underbrace{G}_{\text{Sigma field}}$

$$
\mathcal{F}_n = \sigma \big( \theta_0, \ s_0, \ a_0, \ r(s_0, a_0), \ s_0', \, \dots \, , \ s_{n-1}, \ a_{n-1}, \ r(s_{n-1}, \ a_{n-1}), \ s_{n-1}' \big)
$$

$$
\begin{aligned}
M_{n+1}
& =
\delta_n \ \phi(s_n) - \big( b - A \theta_n \big)
\\ & =
\Big[ r(s_n, a_n) + \gamma \, \phi^\top(s_n) \, \theta_n - \phi^\top(s_n) \, \theta_n \Big] \, \phi(s_n) - \big( b - A \theta_n \big)
\\ & =
\Big[ r(s_n, a_n) \, \phi(s_n) - b \Big] + \Big[ A - \big( \phi(s_n) \, \phi^\top(s_n) - \gamma \, \phi(s_n) \, \phi^\top(s_n') \big) \Big] \, \theta_n
\\
\because \quad & \gamma \, \phi(s_n')^\top \, \theta_n \, \phi(s_n) = \gamma \, \phi(s_n) \, \phi^\top(s_n') \theta_n
\end{aligned}
$$

We have ${(a+b)}^2 \leq 2 a^2 + 2 b^2$

$$
\implies
{\Vert M_{n+1} \Vert}^2
\leq
2 {\Big\Vert \underbrace{ r(s_n, a_n) \, \phi(s_n) }_{\mathbb{E}[b]} - b \Big\Vert}^2 + 2 {\Big\Vert \underbrace{ A - \big( \phi(s_n) \, \phi^\top(s_n) - \gamma \, \phi(s_n) \, \phi^\top(s_n') \big) }_{{\Vert \theta_n \Vert}^2} \Big\Vert}^2
\leq
k \Big[ 1 + {\Vert \theta_n \Vert}^2 \Big]
$$

Monotonicity property of conditional expressions: $X \leq Y \implies \mathbb{E}[X] \leq \mathbb{E}[Y]$

$$
\implies \mathbb{E} \big[ {\Vert M_{n+1} \Vert}^2 \mid \mathcal{F}_n \big] \leq \mathbb{E} \Big[ k \big[ 1 + {\Vert \theta_n \Vert}^2 \big] \Big| \mathcal{F}_n \Big] = k \big[ 1 + {\Vert \theta_n \Vert}^2 \big]
$$

Conditional expectation of the second moment; We need noise terms to be eliminated.

Expectation of the second moment needs to be finite (?)

We now verify **(a)**; To show

$$
\mathbb{E}{\Vert M_n \Vert}^2 < \infty, \ \forall \ n \geq 1
$$
Not
$$
\sup_n \mathbb{E}{\Vert M_n \Vert}^2 < \infty
$$

$$
\begin{aligned}
\theta_{n+1} & = \theta_n + \alpha_n \, \big( b - A \theta_n + M_{n+1} \big) \\
M_{n+1} & = \delta_n \ \phi(s_n) - \big( b - A \theta_n \big)
\\ & = \Big[ r(s_n, a_n) \, \phi(s_n) - b \Big] + \Big[ A - \big( \phi(s_n) \, \phi^\top(s_n) - \gamma \, \phi(s_n) \, \phi^\top(s_n') \big) \Big] \, \theta_n
\end{aligned}
$$

$$
{\Vert M_{n+1} \Vert} \leq k_1 + k_2 \Vert \theta_n \Vert \leq k' [1 + \Vert \theta_n \Vert], \quad \text{where } k' = \max \{ k_1, k_2 \}
$$

$$
\theta_{1} = \theta_0 + \alpha_0 \, \delta_0 \, \phi(s_0) = \theta_0 + \alpha_0 \, \Big[ r(s_0, a_0) \, \phi(s_0) + \big( \gamma \, \phi^\top(s_0') \, \phi(s_0') - \phi^\top(s_0) \, \phi(s_0) \big) \, \theta_0 \Big], \qquad \Vert \theta \Vert \leq c
$$

$$
\vert X \vert \leq c \implies \mathbb{E} \big[ \vert X \vert \big] \leq c
$$

$$
h_c(\theta) = \frac{h(c \, \theta)}{c}, \quad c \geq 1, \qquad \quad \lim_{c \to \infty} h_c(\theta) = h_{\infty}(\theta), \qquad \quad \dot\theta(t) = h_{\infty}(\theta(t))
$$

Let it's ($h_{\infty}$) origin be GAS. Equilibrium $h_{\infty}(\theta) = - A \theta$

$$
h(\theta) = b - A \theta
\implies
h_c(\theta) = \frac{h(c \, \theta)}{c} = \frac{b - A (c \, \theta)}{c} = \frac{b}{c} - A \theta
$$

$$
\text{As } c \to \infty \implies h_{\infty}(\theta) = - A \theta
$$

$$
\dot\theta(t) = - A \theta(t)
$$

$$
V(\theta) = \frac{1}{2} {\Vert \theta \Vert}^2, \qquad \quad V(\theta) = 0 \ \text{ iff } \ \Vert \theta \Vert = 0 \iff \theta = 0
$$

$$
\frac{d}{dt} V(\theta(t)) = \nabla \, V^\top(\theta(t)) \, h_{\infty}(\theta(t)) < \infty
$$

$\xrightarrow{?} - \theta^\top A \theta < 0, \ \forall \ \theta \neq 0$

---

How to find the optimal policy? $\to$ A control problem

Easy for small MDPs, but what about large state-action space?

---

