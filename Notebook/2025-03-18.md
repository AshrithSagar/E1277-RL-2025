# RL | 2025-03-18

## Linear function approximation

Markov noise

$$
\theta_{n+1} = \theta_n + \alpha_n \Big[ r(s_n, a_n) + \gamma \Phi^\top(s_n') \theta_n - \Phi^\top(s_n) \theta_n \Big] \Phi(s_n)
$$

$$
\begin{rcases}
\begin{aligned}
s_n & \sim d_\mu(\cdot) \\
a_n & \sim \mu(\cdot \mid s_n) \\
s_n' & \sim P(\cdot \mid s_n, a_n)
\end{aligned}
\end{rcases}
\ (s_n, a_n, s_n') \text{ is i.i.d.}
$$

No need $s_n, a_n$ as such, what is needed is $r(s_n, a_n)$ in the update rules.

Why should this algorithm work?

If it were a gradient descent algorithm, atleast it would go to some local minima or some saddle point.

We can write this as

$$
\theta_{n+1} = \theta_n + \alpha_n \Big[ b - A \theta_n + M_{n+1} \Big], \\ \text{where } b = \Phi^\top D_\mu r_\mu, \quad A = \Phi^\top D_\mu (I - \gamma P_\mu) \Phi, \quad M_{n+1} = \delta_n \Phi(s_n) - (b - A \theta_n)
$$

Knowledge of $P$ has some nuance. In one case, we need to know $P$, but here, we just need to know the sample $(s')$ that is sampled from $P$. Knowledge of $P$ exactly is not required here.

> Nobody knows anything. Always question.

Without the $M_{n+1}$ term, which is the noise, we have the noiseless version, and we're interested to see if the noiseless version works in theory at the very least, or not.

~ Here, $A$ is not symmetric, hence the objective function can't be written as the gradient of any function.

If it were, we wouldn't need SA theory, SGD tools would be sufficient.

~ Hessian is always symmetric?

Now, the update rule is closely connected to this ODE

$$
\dot \theta(t) = h(\theta(t)) = b - A \theta(t)
$$

From fundamental theorem of calculus

$$
\theta(t_2) - \theta(t_1) = \int_{t_1}^{t_2} \dot \theta(t) \, dt = \int_{t_1}^{t_2} h(\theta(t)) \, dt \approx h(\theta(t_1)) \, (t_2 - t_1)
$$

$$
\implies \theta(t_2) = \theta(t_1) + (t_2 - t_1) \, h(\theta(t_1))
$$

The connection is that the above algorithm is a Noisy Euler approximation of the ODE.

The approximation is good if $(t_2 - t_1) \to 0$, which is ensured by the conditions that we've imposed on $\alpha_n$, which makes $\alpha_n \to 0$.

Now, we're curious to know if the other way around is possible, i.e., given an ODE, can we cook up an update rule?

These type of insights are very powerful tools.

Now, our idea is to observe some data, make some loose update rule, get the corresponding ODE, which may not be nice. Now, we modify the ODE's and look at it's corresponding update rule, and repeat till we're satisfied with the new ODE at the end.

Now, we shift our attention to study ODEs.

$$
\dot \theta(t) = b - A \theta(t)
$$

**Equilibrium point**: If we start from an equilibrium point, we stay there /~the trajectory stays there.

We can find the equilibrium points by equating $\dot \theta (t) = 0$

$$
\implies b - A \theta = 0 \implies \theta_\ast = A^{-1} b
$$

Now, we're interested in two questions:

- Is $\theta_\ast$ asymptotically stable?
- What is the connection between $\theta_\ast$ and $\theta_\ast'$?

### Is $\theta_\ast$ asymptotically stable?

The answer to this uses Lyapunov theory.

Let $\nabla: \mathbb{R}^d \to \mathbb{R}$ be given by

$$
\nabla (\theta) = \frac{1}{2} {\Vert \theta - \theta_\ast \Vert}^2
$$

Suppose $\nabla V(\theta)^\top h(\theta) < 0, \ \forall \ \theta \neq \theta_\ast$, then

$$
\frac{d}{dt} V(\theta(t)) = \nabla V^\top(\theta(t)) \ \dot\theta(t) = \nabla V^\top(\theta(t)) \ h(\theta(t)) < 0
$$

~ This means that where ever we start from any solution trajectory of the ODE, we eventually go to $\theta_\ast'$ (necessarily).

#### Positive definiteness

Wikipedia defines positive definite matrices should be symmetric. Here we don't define it that way. (?)

> Don't be afraid to question definitions.

$$
\nabla V(\theta) = (\theta - \theta_\ast')
$$

$$
\implies
\nabla V(\theta)^\top h(\theta)
= {(\theta - \theta_\ast')}^\top (b - A \theta)
= {(\theta - \theta_\ast')}^\top A (\theta_\ast' - \theta)
= - {(\theta - \theta_\ast')}^\top A (\theta - \theta_\ast')
$$

**Claim:** $\theta^\top A \theta > 0 \ \forall \ \theta \neq 0$

**Proof:**

Recall that

$$
A = \underbrace{\Phi^\top}_{d\times S} \overbrace{D_\mu}^{S \times S} (\underbrace{I}_{S \times S} - \gamma \overbrace{P_\mu}^{S \times S}) \underbrace{\Phi}_{S \times d}
$$

$$
\implies
\theta^\top A \theta = \theta^\top \Phi^\top D_\mu (I - \gamma P_\mu) \Phi \theta = y^\top \underbrace{D_\mu (I - \gamma P_\mu)}_{B} y, \quad \text{where } y = \Phi \theta, \quad B = D_\mu (I - \gamma P_\mu)
$$

If we could show that $B$ was positive definite, then, provided that $y \neq 0$ for $\theta \neq 0$, we have that $A$ is positive definite.

We impose the condition that $\Phi$ has full column rank.

$\mu$ is such that $d_\mu > 0$.

$$
y^\top D_\mu y - \gamma y^\top D_\mu P_\mu y > 0 \ \forall \ y \neq 0
$$

**Subclaim-1:**

$$
y^\top D_\mu P_\mu y \leq y^\top D_\mu y = {\Vert y \Vert}^2_{D_\mu}
$$

Cauchy-Schwarz inequality

$$
y^\top D_\mu P_\mu y = y^\top D_\mu^{1/2} D_\mu^{1/2} P_\mu y
$$

**Subclaim-2:**

$$
{\Vert P_\mu y \Vert}^2_{D_\mu} \leq {\Vert y \Vert}^2_{D_\mu}
$$

LHS is $\sum_{s} d_\mu(s) \ {(P_\mu^\top(s, \cdot) y)}^2$

**Jensen's inequality**: Suppose $f: \mathbb{R} \to \mathbb{R}$ is convex, then $f(\mathbb{E}X) \leq \mathbb{E} f(X)$.

Let $g(x) = x^2$, $g(\mathbb{E}(Y))$

### Is $\theta_\ast'$ any interesting?

**Claim:**

Recall that

$$
\theta_\ast' = A^{-1} b, \quad \text{where } A = \Phi^{\top} D_\mu (I - \gamma P_\mu) \Phi, \quad b = \Phi^\top D_\mu r_\mu
$$

Then

$$
\Pi T_\mu \Phi \theta_\ast' = \Phi \theta_\ast'
$$

where $\Pi = \Phi {(\Phi^\top D_\mu \Phi)}^{-1} \Phi^\top D_\mu$.

$\theta_\ast'$ satisfies what is known as the projected Bellman equation, where $\Pi T_\mu$ is the projected Bellman operator.

$\Phi \theta_\ast'$ is the fixed point of $\Pi T_\mu$.

We work with the $D_\mu$ norm due to convenience.

Running Markov chain for a long time $\implies$ converges to it's stationary distribution. And for the sample, we need $s'$ to be sampled from this distribution. Convenient.

Ideally, we would like to find $\Phi \theta_\ast$, since it's closest to $J_\mu$ in some sense (picked $D_\mu$ norm).

$\Pi J_\mu = \Phi \theta_\ast$

$T_\mu \Phi \theta_\ast'$

$$
{\Vert J - \Pi V \Vert}^2_{D_\mu} = \frac{1}{2} \min_{\theta} {\Vert J - \Phi \theta \Vert}^2_{D_\mu}
$$

~ In some sense, whenever some algorithm in RL works, it's prolly because such approximations work, if not then not.

---

