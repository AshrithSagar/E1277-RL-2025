# RL | 2025-01-30

## Stochastic shortest path problems

a.k.a **Episodic problems**

Characterised by the existence of a goal/terminal state
- Goal/terminal state: $0$
- Non-terminal state: $1, 2, \dots, n$

Goal/terminal state: $0$

$$
\begin{aligned}
g(0, u, 0)
& =
0, \quad \forall u \in A(0)
\\
P_{00}(u)
& =
1, \quad \forall u \in A(0)
\end{aligned}
$$

Assumed to have no terminal cost.

**Proper policy ($\mu$)**: If the following is satisfied

$$
\rho_\mu \triangleq  \max _{i = 1, 2, \dots, n} P(S_n \neq 0 \mid S_0 = i, \mu) < 1
$$

Let

$$
\bar g(i, u) = \sum_{j=0}^{n} p_{ij}(u) g(i, u, j)
$$

Expected single stage cost in state $i$ under action $u$

---

Define mappings $T$ and $T_\mu$ such that

$$
T, T_\mu: \mathbb{R}^{|S|} \to \mathbb{R}^{|S|}
$$

$$
\mathbb{R}^{|S|} = \{ f \mid f: S \to \mathbb{R} \}
$$

Let $J = (J(1), \ J(2), \ \dots, \ J(n))$

$$
(TJ)(i) = \min_{u \in A(i)} \left[ \bar g(i, u) + \sum_{j=1}^{n} p_{ij}(u) J(j) \right], \quad \forall i = 1, 2, \dots, n
$$

$$
TJ = \Big( (TJ)(1), \ (TJ)(2), \ \dots, \ (TJ)(n)) \Big)
$$

$$
(T_\mu J)(i) = \bar g(i, \mu(i)) + \sum_{j=1}^{n} p_{ij}(\mu(i)) J(j), \quad \forall i = 1, 2, \dots, n
$$

$$
T_\mu J = ((T_\mu J)(1), \ (T_\mu J)(2), \ \dots, \ (T_\mu J)(n)))
$$

$$
P_\mu =
\begin{bmatrix}
p_{11}(\mu(1)) & p_{12}(\mu(1)) & \dots & p_{1n}(\mu(1)) \\
p_{21}(\mu(2)) & p_{22}(\mu(2)) & \dots & p_{2n}(\mu(2)) \\
\vdots & \vdots & \ddots & \vdots \\
p_{n1}(\mu(n)) & p_{n2}(\mu(n)) & \dots & p_{nn}(\mu(n)) \\
\end{bmatrix}
$$

**Note:** The row sum is $\leq 1$, since it's only over the non-terminal states
$$
\sum_{j \in S} p_{ij}(\mu(i)) \leq 1
$$

$$
T_\mu J = \bar g_\mu + P_\mu J
,\quad
\text{where }
\bar g_\mu = \begin{bmatrix} \bar g(1, \mu(1)) \\ \bar g(2, \mu(2)) \\ \vdots \\ \bar g(n, \mu(n)) \end{bmatrix}
$$

$$
T^k J = T(T^{k-1} J), \quad k \geq 0, \quad \text{where } T^0 = I
$$

$$
T^k J = \underbrace{(T \circ T \circ \cdots \circ T)}_{k \text{ times}} \ J
$$

i.e., $k$ times composiiton of $T$ with itself

When $k=2$

$$
\begin{aligned}
\implies
(T^2 J) (i)
& =
T(TJ)(i)
\\ & =
\min_{u\in A(i)} \left[ \bar g(i, u) + \sum_{j=1}^{n} p_{ij}(u)(TJ)(j) \right]
\\ & =
\min_{u\in A(i)} \left[ \bar g(i, u) + \sum_{j=1}^{n} p_{ij}(u) \left( \min_{u \in A(j)} \left[ \bar g(j, u) + \sum_{k=1}^{n} p_{jk}(u) J(k) \right] \right) \right]
\end{aligned}
$$

Interpretation:

$(T^2 J)(i)$ is the optimal cost for a 2-stage problem starting in state $i$, with single stage cost $\bar g(\cdot, \cdot)$, and terminal cost $J(\cdot)$

What is then $(T^k J)(i)$?

$\to$ Optimal cost for a $k$-stage problem with initial state $i$, single stage cost $\bar g(\cdot, \cdot)$, and terminal cost $J(\cdot)$

$$
(T^k J) (i)
= \min_{u\in A(i)} \left[ \bar g(i, u) + \sum_{j\in S} p_{ij}(u)(T^{k-1} J)(j) \right], \quad \forall i = 1, 2, \dots, n
$$

~ Contraction mappings

Dynamic programming, ~can be applied

## Lemma-1: Monotonicity lemma

For any functions $J, \bar J \in \mathbb{R}^n$, s.t. $J(i) \leq \bar J(i), \ \forall i = 1, 2, \dots, n$ and for any stationary policy $\mu$

1.
$$
(T^k J)(i) \leq (T^k \bar J)(i), \quad \forall k \geq 0, \quad \forall i = 1, 2, \dots, n
$$

2.
$$
(T_\mu^k J)(i) \leq (T_\mu^k \bar J)(i), \quad \forall k \geq 0, \quad \forall i = 1, 2, \dots, n
$$

### Proof

#### Part-(1)

Consider $k=1$,

$$
\begin{aligned}
(TJ)(i) & =
\min_{u \in A(i)} \left[ \bar g(i, u) + \sum_{j\in S} p_{ij}(u) J(j) \right]
\\ & \leq
\min_{u \in A(i)} \left[ \bar g(i, u) + \sum_{j\in S} p_{ij}(u) \bar J(j) \right]
\\ & =
(T \bar J)(i), \quad \forall i \in S
\end{aligned}
$$

The rest follows from ~mathematical induction

#### Part-(2)

Follows similarly

## Lemma-2

$\forall k \geq 0$, vector $J = (J(1), \ J(2), \ \dots, \ J(n))$, stationary policy $\mu$ and $r \geq 0$,

1.
$$
(T^k (J + re))(i) \leq (T^k J)(i) + r, \quad \forall i = 1, 2, \dots, n
$$

2.
$$
(T_\mu^k (J + re))(i) \leq (T_\mu^k J)(i) + r, \quad \forall i = 1, 2, \dots, n
$$

Here $e = (1, 1, \dots, 1)^\top$, i.e., the $n$-vector of all 1's

The inequality is reversed if $r < 0$

### Proof

#### Part-(1)

Consider $k=1$,

$$
\begin{aligned}
(T^k (J + re))(i)
& =
\min_{u \in A(i)} \left[ \bar g(i, u) + \sum_{j\in S} p_{ij}(u) \Big((J + re)(j)\Big) \right], \quad \forall i = 1, 2, \dots, n
\\ & =
\min_{u \in A(i)} \left[ \bar g(i, u) + \sum_{j\in S} p_{ij}(u) J(j) + r \sum_{j\in S} p_{ij}(u) \right]
\\ & \leq
\min_{u \in A(i)} \left[ \bar g(i, u) + \sum_{j\in S} p_{ij}(u) J(j) \right] + r
\\ & =
(TJ)(i) + r
\end{aligned}
$$

The rest follows using ~mathematical induction

#### Part-(2)

Follows similarly

![J+re interpretation](./TeX/2025-01-30/1.png)
$(J+re)$ interpretation

## Assumptions

**(A).** There exists atleast one proper policy

**(B).** For every improper $\mu$, $J_\mu (i) = \infty$ for atleast one state $i$

## Proposition-1

**(a).** For a proper policy $\mu$, the associated cost vector $J_\mu$ satisfies

$$
\lim_{k \to \infty} (T\mu^k J)(i) = J_\mu (i), \quad \forall i = 1, 2, \dots, n
$$

for every $J \in \mathbb{R}^n$. Moreover,

$$
J_\mu = T_\mu J_\mu
\label{eq:unique-fixed-point-eq1}
$$

and $J_\mu$ is the unique solution for this equation $\eqref{eq:unique-fixed-point-eq1}$.

**(b).** A stationary policy satisfying for some vector $J$,

$$
J(i) \geq T_\mu J(i), \quad \forall i = 1, 2, \dots, n
$$

is <u>proper</u>.

---

~Implications:

Sequence of functions $J, \quad T_\mu J, \quad T(T_\mu J) = T_\mu^2 J, \quad T_\mu^3 J, \ \cdots \ \longrightarrow J_\mu$, converges to $J_\mu$

$J_\mu = T_\mu J_\mu$ means

$$
J_\mu (i) = \bar g(i, \mu(i)) + \sum_{j \in S} p_{ij}\left(\mu(i)\right) J_\mu(j)
\tag{Bellman equation for policy $\mu$}
$$

~Fixed point for $T_\mu$

Fixed point

- For any function $J: \mathbb{R}^n \to \mathbb{R}^n$, the fixed point of $J$ is a point $x\in \mathbb{R}^n$ s.t. $x = J(x)$
- ~Fixed point for a function

### Proof

#### Part-(a)

Recall $T_\mu J = \bar g_\mu + P_\mu J$

$$
T_\mu^2 J = \bar g_\mu + P_\mu (T_\mu J) = \bar g_\mu + P_\mu \bar g_\mu + P_\mu^2 \bar g_\mu
$$

Proceeding similarly,

$$
T_\mu^k J = P_\mu^k J + \sum_{m=0}^{k-1} P_\mu^m \bar g_\mu
$$

We have seen that

$$
P(S_k \neq 0 \mid S_0 = i, \mu) \leq \rho_\mu^{\lfloor \frac{k}{n} \rfloor}, \quad \forall i = 1, 2, \dots, n
$$

Then, ~observe that $J: \mathbb{R}^n \to \mathbb{R}^n$

$$
\begin{aligned}
(P^k_\mu J)(i) & =
\sum_{k=1}^{n} P(S_k = j \mid S_0 = i, \mu) J(j)
\\ & \leq
\sum_{k=1}^{n} P(S_k = j \mid S_0 = i, \mu) \max_{j=1, 2, \dots, n} J(j)
\\ & =
P(S_k \neq 0 \mid S_0 = i, \mu) \max_{j=1, 2, \dots, n} J(j)
\\ & \leq
\rho_\mu^{\lfloor \frac{k}{n} \rfloor} \max_{j=1, 2, \dots, n} J(j)
\\ &
\longrightarrow 0 \text{ as } k \to \infty
\end{aligned}
$$

Thus,

$$
\lim_{k \to \infty} T_\mu^k J = \lim_{k \to \infty} \sum_{m=0}^{k-1} P_\mu^m g_\mu = J_\mu
$$

By definition, and letting $k \to \infty$ on either side, we obtain

$$
J_\mu = g_\mu + P_\mu J_\mu \quad \text{or} \quad J_\mu = T_\mu J_\mu
$$

~Now to check for uniqueness of the fixed point

Suppose $\exists \ \bar J_\mu$ s.t. $\bar J_\mu = T_\mu \bar J_\mu$

Applying $T_\mu$ repeatedly gives us

$$
\bar J_\mu, \quad T_\mu \bar J_\mu, \quad T_\mu^2 \bar J_\mu, \quad \dots, \quad \lim_{k \to \infty}T_\mu^k \bar J_\mu \to J_\mu
$$

---

We have shown

1.
$$
J_\mu = \lim_{k \to \infty}T_\mu^k \bar J_\mu \to J_\mu
$$

for any $J \in \mathbb{R^n}$

2. $J_\mu = T_\mu J_\mu$

Suppose $\bar J_\mu$ is another point in $\mathbb{R}^n$ s.t. $\bar J_\mu = T_\mu \bar J_\mu$

$$
\bar J_\mu = T_\mu \bar J_\mu = T_\mu^2 \bar J_\mu = T_\mu^3 \bar J_\mu = \dots \implies \lim_{k \to \infty} T_\mu^k \bar J_\mu = J_\mu
$$

---

